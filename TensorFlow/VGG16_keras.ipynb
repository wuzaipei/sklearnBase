{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用迁移学习的思想，以VGG16作为模板搭建模型，训练识别手写字体\n",
    "# 引入VGG16模块\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 加载字体库作为训练样本\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# 加载OpenCV（在命令行中窗口中输入pip install opencv-python），这里为了后期对图像的处理，\n",
    "# 大家使用pip install C:\\Users\\28542\\Downloads\\opencv_python-3.4.1+contrib-cp35-cp35m-win_amd64.whl\n",
    "# 比如尺寸变化和Channel变化。这些变化是为了使图像满足VGG16所需要的输入格式\n",
    "import cv2\n",
    "import h5py as h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,638,218\n",
      "Trainable params: 18,923,530\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立一个模型，其类型是Keras的Model类对象，我们构建的模型会将VGG16顶层去掉，只保留其余的网络\n",
    "# 结构。这里用include_top = False表明我们迁移除顶层(顶层及vgg的最后一层)以外的其余网络结构到自己的模型中\n",
    "# VGG模型对于输入图像数据要求高宽至少为48个像素点，由于硬件配置限制，我们选用48个像素点而不是原来\n",
    "# VGG16所采用的224个像素点。即使这样仍然需要24GB以上的内存，或者使用数据生成器\n",
    "model_vgg = VGG16(include_top=False, weights='imagenet', input_shape=(48, 48, 3))\n",
    "for layer in model_vgg.layers:\n",
    "    layer.trainable = False # 设置不可以训练了，也就是参数不动\n",
    "model = Flatten(name='flatten')(model_vgg.output)\n",
    "model = Dense(4096, activation='relu', name='fc1')(model)\n",
    "model = Dense(4096, activation='relu', name='fc2')(model)\n",
    "model = Dropout(0.5)(model)\n",
    "model = Dense(10, activation='softmax')(model)\n",
    "model_vgg_mnist = Model(inputs=model_vgg.input, outputs=model, name='vgg16')\n",
    "\n",
    "# 打印模型结构，包括所需要的参数\n",
    "model_vgg_mnist.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.05, decay=1e-5) # decay学习率的衰减参数\n",
    "model_vgg_mnist.compile(loss='categorical_crossentropy',\n",
    "                                 optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# 因为VGG16对网络输入层的要求，我们用OpenCV把图像从32*32变成224*224，把黑白图像转成RGB图像\n",
    "# 并把训练数据转化成张量形式，供keras输入\n",
    "def load_data(path=\"./test_data/mnist.npz\"):\n",
    "    f = np.load(path)\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']\n",
    "    f.close()\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "\n",
    "X_train, y_train = X_train[:10000], y_train[:10000]\n",
    "X_test, y_test = X_test[:1000], y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [cv2.cvtColor(cv2.resize(i, (48, 48)), cv2.COLOR_GRAY2RGB)\n",
    "           for i in X_train]\n",
    "X_test = [cv2.cvtColor(cv2.resize(i, (48, 48)), cv2.COLOR_GRAY2RGB)\n",
    "          for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 48, 48, 3), (10000,))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train).shape, np.array(y_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 48, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0][np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## np.newaxis:增加一个维度\n",
    "X_train = np.concatenate([arr[np.newaxis] for arr in X_train]).astype('float32')\n",
    "\n",
    "X_test = np.concatenate([arr[np.newaxis] for arr in X_test]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 48, 48, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 48, 48, 3)\n",
      "(1000, 48, 48, 3)\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 1.3963 - acc: 0.5651 - val_loss: 1.4003 - val_acc: 0.4190\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 9s 853us/step - loss: 0.7563 - acc: 0.7653 - val_loss: 0.7394 - val_acc: 0.7520\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 9s 856us/step - loss: 0.5668 - acc: 0.8197 - val_loss: 1.3852 - val_acc: 0.5420\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 9s 850us/step - loss: 0.5087 - acc: 0.8348 - val_loss: 1.2686 - val_acc: 0.5560\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 9s 872us/step - loss: 0.4188 - acc: 0.8694 - val_loss: 0.3756 - val_acc: 0.8890\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 9s 855us/step - loss: 0.4252 - acc: 0.8652 - val_loss: 0.6861 - val_acc: 0.7660\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 9s 870us/step - loss: 0.3316 - acc: 0.8941 - val_loss: 0.4637 - val_acc: 0.8450\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 9s 855us/step - loss: 0.3260 - acc: 0.8948 - val_loss: 1.0737 - val_acc: 0.6780\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 9s 866us/step - loss: 0.2834 - acc: 0.9096 - val_loss: 0.4343 - val_acc: 0.8610\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.2745 - acc: 0.9110 - val_loss: 0.3022 - val_acc: 0.9060\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.2572 - acc: 0.9174 - val_loss: 0.9065 - val_acc: 0.7420\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 9s 857us/step - loss: 0.2564 - acc: 0.9195 - val_loss: 0.2411 - val_acc: 0.9280\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.2584 - acc: 0.9181 - val_loss: 0.4842 - val_acc: 0.8200\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.2347 - acc: 0.9226 - val_loss: 0.3906 - val_acc: 0.8650\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.2115 - acc: 0.9306 - val_loss: 0.4030 - val_acc: 0.8730\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.2160 - acc: 0.9303 - val_loss: 0.2559 - val_acc: 0.9130\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 9s 881us/step - loss: 0.1893 - acc: 0.9385 - val_loss: 0.3949 - val_acc: 0.8580\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 9s 855us/step - loss: 0.1936 - acc: 0.9371 - val_loss: 0.3148 - val_acc: 0.8940\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 9s 875us/step - loss: 0.2027 - acc: 0.9351 - val_loss: 0.2875 - val_acc: 0.9040\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.1824 - acc: 0.9419 - val_loss: 0.5767 - val_acc: 0.8220\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 9s 868us/step - loss: 0.1959 - acc: 0.9384 - val_loss: 0.2175 - val_acc: 0.9330\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 9s 852us/step - loss: 0.1854 - acc: 0.9413 - val_loss: 0.4539 - val_acc: 0.8620\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 9s 853us/step - loss: 0.1633 - acc: 0.9481 - val_loss: 0.4484 - val_acc: 0.8600\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 9s 856us/step - loss: 0.1695 - acc: 0.9433 - val_loss: 0.6081 - val_acc: 0.8160\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 9s 877us/step - loss: 0.2010 - acc: 0.9409 - val_loss: 0.4542 - val_acc: 0.8260\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.1518 - acc: 0.9517 - val_loss: 0.1950 - val_acc: 0.9350\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.1412 - acc: 0.9536 - val_loss: 0.1707 - val_acc: 0.9400\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.1376 - acc: 0.9554 - val_loss: 0.4351 - val_acc: 0.8650\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 9s 855us/step - loss: 0.1584 - acc: 0.9489 - val_loss: 0.3235 - val_acc: 0.8890\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 9s 873us/step - loss: 0.1297 - acc: 0.9591 - val_loss: 0.6141 - val_acc: 0.7880\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.1857 - acc: 0.9460 - val_loss: 0.1622 - val_acc: 0.9450\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 9s 883us/step - loss: 0.1216 - acc: 0.9630 - val_loss: 0.1519 - val_acc: 0.9490\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 9s 857us/step - loss: 0.1209 - acc: 0.9620 - val_loss: 1.1652 - val_acc: 0.6940\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 9s 855us/step - loss: 0.1772 - acc: 0.9478 - val_loss: 0.1520 - val_acc: 0.9470\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.1208 - acc: 0.9618 - val_loss: 0.4153 - val_acc: 0.8670\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 9s 856us/step - loss: 0.1240 - acc: 0.9613 - val_loss: 0.4679 - val_acc: 0.8450\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 9s 894us/step - loss: 0.1576 - acc: 0.9549 - val_loss: 0.1894 - val_acc: 0.9400\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 9s 855us/step - loss: 0.1116 - acc: 0.9642 - val_loss: 0.2195 - val_acc: 0.9220\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 9s 861us/step - loss: 0.1180 - acc: 0.9617 - val_loss: 0.8338 - val_acc: 0.7830\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 9s 860us/step - loss: 0.1360 - acc: 0.9569 - val_loss: 0.1943 - val_acc: 0.9320\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.1121 - acc: 0.9643 - val_loss: 0.5626 - val_acc: 0.8370\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 9s 861us/step - loss: 0.1611 - acc: 0.9536 - val_loss: 0.2070 - val_acc: 0.9270\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 9s 856us/step - loss: 0.1059 - acc: 0.9659 - val_loss: 0.1709 - val_acc: 0.9510\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.1058 - acc: 0.9667 - val_loss: 0.1331 - val_acc: 0.9550\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.1262 - acc: 0.9608 - val_loss: 0.3669 - val_acc: 0.8800\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 9s 882us/step - loss: 0.1058 - acc: 0.9651 - val_loss: 0.5574 - val_acc: 0.8580\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 9s 879us/step - loss: 0.1088 - acc: 0.9654 - val_loss: 1.8517 - val_acc: 0.6370\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 9s 869us/step - loss: 0.3125 - acc: 0.9385 - val_loss: 0.1675 - val_acc: 0.9480\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.1089 - acc: 0.9658 - val_loss: 0.1568 - val_acc: 0.9470\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.1042 - acc: 0.9675 - val_loss: 0.2610 - val_acc: 0.9160\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.1093 - acc: 0.9638 - val_loss: 0.3593 - val_acc: 0.8850\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 9s 879us/step - loss: 0.0995 - acc: 0.9678 - val_loss: 0.1592 - val_acc: 0.9480\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.0962 - acc: 0.9673 - val_loss: 0.1378 - val_acc: 0.9530\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.0935 - acc: 0.9696 - val_loss: 0.4058 - val_acc: 0.8790\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.0981 - acc: 0.9682 - val_loss: 0.1489 - val_acc: 0.9510\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.0985 - acc: 0.9688 - val_loss: 0.3946 - val_acc: 0.8710\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.0940 - acc: 0.9688 - val_loss: 0.1739 - val_acc: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.0922 - acc: 0.9711 - val_loss: 0.2664 - val_acc: 0.9190\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 9s 865us/step - loss: 0.0984 - acc: 0.9687 - val_loss: 0.9320 - val_acc: 0.7250\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.1260 - acc: 0.9643 - val_loss: 0.6343 - val_acc: 0.8080\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.1437 - acc: 0.9587 - val_loss: 0.1410 - val_acc: 0.9520\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.0870 - acc: 0.9717 - val_loss: 0.1379 - val_acc: 0.9590\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 9s 860us/step - loss: 0.0817 - acc: 0.9745 - val_loss: 0.9795 - val_acc: 0.7600\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 9s 861us/step - loss: 0.1123 - acc: 0.9673 - val_loss: 0.3600 - val_acc: 0.8880\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 9s 865us/step - loss: 0.0837 - acc: 0.9737 - val_loss: 0.1366 - val_acc: 0.9590\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 9s 861us/step - loss: 0.0853 - acc: 0.9729 - val_loss: 0.3355 - val_acc: 0.8850\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.0808 - acc: 0.9731 - val_loss: 0.1254 - val_acc: 0.9620\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.0779 - acc: 0.9762 - val_loss: 0.1395 - val_acc: 0.9550\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 9s 860us/step - loss: 0.0761 - acc: 0.9768 - val_loss: 0.1372 - val_acc: 0.9590\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 9s 857us/step - loss: 0.0792 - acc: 0.9747 - val_loss: 0.1515 - val_acc: 0.9530\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 9s 871us/step - loss: 0.0725 - acc: 0.9775 - val_loss: 0.3066 - val_acc: 0.9100\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 9s 867us/step - loss: 0.0783 - acc: 0.9753 - val_loss: 0.1700 - val_acc: 0.9500\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 9s 857us/step - loss: 0.0698 - acc: 0.9794 - val_loss: 0.5811 - val_acc: 0.8500\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 9s 861us/step - loss: 0.0850 - acc: 0.9735 - val_loss: 0.4009 - val_acc: 0.8710\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.0812 - acc: 0.9732 - val_loss: 0.4489 - val_acc: 0.8850\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 9s 860us/step - loss: 0.0903 - acc: 0.9711 - val_loss: 0.2676 - val_acc: 0.9000\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.0716 - acc: 0.9772 - val_loss: 0.1534 - val_acc: 0.9540\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.0682 - acc: 0.9782 - val_loss: 0.1364 - val_acc: 0.9600\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 9s 857us/step - loss: 0.0674 - acc: 0.9786 - val_loss: 0.1580 - val_acc: 0.9450\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 9s 859us/step - loss: 0.0645 - acc: 0.9796 - val_loss: 0.1262 - val_acc: 0.9570\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.0711 - acc: 0.9771 - val_loss: 0.2059 - val_acc: 0.9280\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 9s 858us/step - loss: 0.0659 - acc: 0.9790 - val_loss: 0.4925 - val_acc: 0.8560\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 9s 860us/step - loss: 0.0715 - acc: 0.9757 - val_loss: 1.2620 - val_acc: 0.6880\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 9s 860us/step - loss: 0.1060 - acc: 0.9708 - val_loss: 0.3687 - val_acc: 0.8820\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 9s 862us/step - loss: 0.0721 - acc: 0.9780 - val_loss: 0.1265 - val_acc: 0.9580\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 9s 867us/step - loss: 0.0601 - acc: 0.9822 - val_loss: 0.1637 - val_acc: 0.9450\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 9s 866us/step - loss: 0.0599 - acc: 0.9820 - val_loss: 0.1409 - val_acc: 0.9520\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 9s 882us/step - loss: 0.0603 - acc: 0.9811 - val_loss: 0.2256 - val_acc: 0.9350\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 9s 877us/step - loss: 0.0586 - acc: 0.9825 - val_loss: 0.1781 - val_acc: 0.9410\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 9s 876us/step - loss: 0.0597 - acc: 0.9803 - val_loss: 1.4925 - val_acc: 0.7420\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 9s 864us/step - loss: 0.1200 - acc: 0.9691 - val_loss: 0.1829 - val_acc: 0.9380\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 9s 860us/step - loss: 0.0615 - acc: 0.9801 - val_loss: 0.1219 - val_acc: 0.9610\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.0578 - acc: 0.9815 - val_loss: 0.1599 - val_acc: 0.9500\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 9s 864us/step - loss: 0.0580 - acc: 0.9822 - val_loss: 0.1202 - val_acc: 0.9650\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 9s 868us/step - loss: 0.0582 - acc: 0.9825 - val_loss: 0.2074 - val_acc: 0.9390\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 9s 888us/step - loss: 0.0564 - acc: 0.9833 - val_loss: 0.1361 - val_acc: 0.9570\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.0573 - acc: 0.9826 - val_loss: 0.1538 - val_acc: 0.9550\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 9s 863us/step - loss: 0.0593 - acc: 0.9810 - val_loss: 0.1224 - val_acc: 0.9600\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 9s 869us/step - loss: 0.0534 - acc: 0.9841 - val_loss: 0.1761 - val_acc: 0.9450\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 9s 867us/step - loss: 0.0525 - acc: 0.9845 - val_loss: 0.1763 - val_acc: 0.9470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ed5a0a6be0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "\n",
    "def tran_y(y):\n",
    "    y_ohe = np.zeros(10)\n",
    "    y_ohe[y] = 1\n",
    "    return y_ohe\n",
    "\n",
    "\n",
    "y_train_ohe = np.array([tran_y(y_train[i]) for i in range(len(y_train))])\n",
    "y_test_ohe = np.array([tran_y(y_test[i]) for i in range(len(y_test))])\n",
    "\n",
    "model_vgg_mnist.fit(X_train, y_train_ohe, validation_data=(X_test, y_test_ohe),\n",
    "                             epochs=100, batch_size=128,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
